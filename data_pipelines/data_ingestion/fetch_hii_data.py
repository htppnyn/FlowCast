import os
import requests
from bs4 import BeautifulSoup
from tqdm import tqdm

def get_links(url):
    """ ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å URL """
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")
        return [a['href'] for a in soup.find_all("a", href=True) if not a['href'].startswith("?")]
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Error fetching links from {url}: {e}")
        return []

def download_csv(file_url, file_path):
    """ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ """
    if not os.path.exists(file_path):
        try:
            r = requests.get(file_url, timeout=15)
            r.raise_for_status()
            with open(file_path, 'wb') as f:
                f.write(r.content)
            print(f"‚úÖ Downloaded: {file_url}")
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Error downloading {file_url}: {e}")

def fetch_rainfall_data(base_url, download_path, year=None):
    os.makedirs(download_path, exist_ok=True)  # ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á

    year_links = [y for y in get_links(base_url) if y.endswith('/') and y[:-1].isdigit()]
    
    # ‡∏´‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏µ, ‡∏à‡∏∞‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏Ñ‡πà‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    if year:
        year_links = [y for y in year_links if y[:-1] == str(year)]

    for year in tqdm(year_links, desc="üìÖ Fetching Years"):
        year_url = os.path.join(base_url, year)
        year_path = os.path.join(download_path, year.strip("/"))
        os.makedirs(year_path, exist_ok=True)

        month_links = get_links(year_url)
        for month in tqdm(month_links, desc=f"üìÜ {year.strip('/')} - Fetching Months", leave=False):
            month_url = os.path.join(year_url, month)
            month_path = os.path.join(year_path, month.strip("/"))
            os.makedirs(month_path, exist_ok=True)

            file_links = [f for f in get_links(month_url) if f.endswith(".csv")]
            for file in tqdm(file_links, desc=f"üìÇ {month.strip('/')} - Fetching Files", leave=False):
                file_url = os.path.join(month_url, file)
                file_path = os.path.join(month_path, file)
                download_csv(file_url, file_path)


### For testing purposes only ###
# BASE_URL = "https://tiservice.hii.or.th/opendata/data_catalog/hourly_rain/"
# DOWNLOAD_PATH = "./rain_data"
# fetch_rainfall_data(BASE_URL, DOWNLOAD_PATH, year=2025)
